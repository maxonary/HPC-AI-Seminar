# Building a Responsible Al Framework
Insights from Intel by Lama Nachman 
Intel Sr Fellow, Director of Intelligent Systems Research, Intel Labs

![AI Progress over the last 15 years](4-images/ai-progress-09-23.png)
**Stagnating developments in acuracy before deep learning**:
- Object recognition
- Speech recognition
- NLP (Natural Language Processing)

**2 pivotal moments in AI**:
- Moore's Law, processing power doubling every 18 months
- High level concept frameworks making training accessible to everyone

Before:
- Bespoke models ASR, NLP, CV
- High cost of development

Now:
- Open source frameworks
- Pre-trained models
- Transfer learning
- Generative models
- GPU acceleration

**From 2015 a lot of concerns emerged:**
![Ethical Concerns of AI](4-images/ai-concerns.png)
**Bias - Privacy - Security - Safety - Accountability - Transparency - Fairness - Surveillance**

## Intel's journey to responsible AI
RAI - Responsible AI pursues positive outcomes and prevents negative results
![RAI Journey so far](4-images/rai-journey.png)

People associate Intel with hardware, but they are also a software company:
- **OpenVINO** - Toolkit for deploying AI models on Intel hardware
- **OneAPI** - Toolkit for programming across different Intel hardware

**Intel established a ruleset for RAI**:
![Intel's RAI Ruleset](4-images/rai-governance.png)
- Internal governance about ensuring AI adhears to ethical standards
- External governance about ensuring AI is used responsibly

Intel Advisery council built an AI expert network to provide capabilities for various AI projects. 

## Human Al Collaboration
"The things we are good at, AI is horrible at. The things AI is good at, we are horrible at." - Lama Nachman

**AI is good at**:
- Recognizing patterns
- Processing large amounts of data
- Making predictions

**Humans are good at**:
- Creativity
- Empathy
- Common sense
- Ethical reasoning

**People will collaborate with AI**:
![Smart Task Spaces in Manufacturing](4-images/human-ai-manufacturing.png)
![Multimodal Activity Recognition in Industrial Environments](4-images/multimodal-industry.png)

People shouldn't blindly trust AI output, but trust the process that created the AI.
- **Explainability** - Understanding how AI came to a decision
- **Transparency** - Understanding the data that was used
- **Edibility** - Ability to change the AI model

![MARIE - Supporting trust calibration across design + engineering](4-images/ai-trust-calibration.png)

**AI and AR in Robotics**:
![AR Based Programming by Demonstration](4-images/ar-robot-programming.png)

Can robots understand how humans colaborate?
Robots shouldn't avoid humans, but understand them and predict their actions.