# Itel Architecture & Platform Evolution
A brief history by Shesha Krishnapura, Intel Fellow and Intel IT CTO - July 2024

## 1. Introduction
Nobody seems to know the interal architecture of Intel processors better than Shesha Krishnapura. He has been with Intel for over 30 years and has seen the evolution of Intel processors from the 8086 to the latest 7nm processors. In this lecture, he gives us a brief history of Intel processors and the platforms they run on.

### Foundational Concepts
- **Silicon Atoms**: Only 0.24 nm large atom. 
- **Transistor**: 
Nanometer sized semiconductor device from silicon used to amplify or switch electronic signals.
Consist of:
    - Gate: Controls the flow of electrons
    - Source: Where electrons come from
    - Drain: Where electrons go
- **PPA**: Power, Performance, Area - increases performance, reduces power, and reduces area.
- **Wafer vs Die**: A wafer is a thin slice of semiconductor material from which chips are made. A die is a single chip on a wafer.
- **Cache**: A small amount of memory that is faster than the main memory and is used to store frequently accessed data.


- **Moore's Law**: The number of transistors on a chip doubles every two years.
- **Tick-Tock Model**: Intel's strategy of alternating between shrinking the process technology and introducing a new microarchitecture.


## Kitchen Analogy to Explain Chip Design
Imagine a Kitchen that has a fixed size and you want to cook more dishes. You can either increase the number of burners or make the burners more efficient. This is similar to the PPA concept in processors.

The burners are the **cores**, the kitchen is the chip, and the dishes are the applications. 

If you increase the number of burners, you need to increase the size of the kitchen. Else you can make the burners more efficient. Increase gas flow - increase **cloock speed**. 

The fridge is the **cache**. The bigger the fridge, the more ingredients you can store. The closer the fridge to the burners, the faster you can cook.

The supermarket is the memory. The closer the supermarket to the kitchen, the faster you can get ingredients. There are obstacles to get to the supermarket, like traffic, which is the **latency**, essentially the time it takes to get to the supermarket and back.  
The amount of items you can transfer is the **bandwidth**.

If there is a congestion (traffic jam) in the supermarket, you can't get the ingredients you need. This is the **memory bandwidth**.

To reduce the congestion, you can increase the number of lanes to the supermarket. This is the **memory channel**.

The relationship between latency and bantwidth is the **memory hierarchy**. The closer the memory is to the processor, the lower the latency and higher the bandwidth.

## Building a HPC System
Questions to ask when designing a HPC system:
1. What software do you want to run? - Workload
2. What hardware do you need?
3. What is the power budget?
4. What is the cooling budget?
5. What is the space budget?